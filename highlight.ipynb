{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms as tfs\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader,random_split,TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../features.pkl\")\n",
    "\n",
    "features_ori = np.zeros([3688,384],dtype=np.float64)\n",
    "for i,f in enumerate(df['feature']):\n",
    "    features_ori[i] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3688"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "features_zero = (features_ori-features_ori.mean(axis=0))/(features_ori.std(axis=0)+0.000001)\n",
    "features = features_zero[:,:]\n",
    "\n",
    "fea_dim = len(features[0])\n",
    "print(fea_dim)\n",
    "MyModel =  nn.Sequential(\n",
    "            nn.Linear(fea_dim,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,1),\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = TensorDataset(torch.tensor(features,dtype=torch.float),torch.tensor(df['label'].values.astype(np.int)))\n",
    "train_size = int(len(dataset)*0.7)\n",
    "val_size = (len(dataset) - train_size)\n",
    "\n",
    "test_size = len(dataset) - train_size- val_size\n",
    "train_set,val_set,test_set = random_split(dataset,[train_size,val_size,test_size])\n",
    "\n",
    "train_loader = DataLoader(train_set,batch_size=128,shuffle=True)\n",
    "val_loader = DataLoader(val_set,batch_size=64,shuffle=False)\n",
    "test_loader = DataLoader(test_set,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_epoch(model,data_loader,criterion,optimizer,device):\n",
    "    \n",
    "    # 训练\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(),lr = 0.01)\n",
    "    for i,(fea,target) in enumerate(data_loader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        fea = fea.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        out = model(fea).squeeze()\n",
    "        # 可能有问题\n",
    "        loss = criterion(out,target.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('finished 1 train epoch')\n",
    "        \n",
    "def validate(model,data_loader,device,show=False):\n",
    "    correct = 0.\n",
    "    total_num = 0.\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    for i,(img,target) in enumerate(data_loader):\n",
    "        img = img.to(device)\n",
    "        target = target.to(device)\n",
    "        out = model(img).squeeze()\n",
    "        \n",
    "        correct += torch.sum((torch.round(nn.Sigmoid()(out))==target)).cpu().item()\n",
    "        total_num += len(target)\n",
    "        \n",
    "        if show:\n",
    "            print(nn.Sigmoid()(out))\n",
    "            print(target)\n",
    "            \n",
    "    print(correct,total_num)\n",
    "    print('accuracy: %f\\n'%(correct/total_num))\n",
    "    return correct/total_num\n",
    "        \n",
    "    \n",
    "def train(model,train_loader,test_loader,criterion,optimizer,epoch_num=1, device='cpu'):\n",
    "    best = 0.\n",
    "    for i in range(epoch_num):\n",
    "        train_epoch(model,train_loader,criterion,optimizer,device)\n",
    "        print('epoch %d'%i)\n",
    "        acc = validate(model,test_loader,device)\n",
    "        if acc > best:\n",
    "            best = acc\n",
    "#             torch.save(model,'./best_model_epoch%d_acc_%.3f.pkl'%(i,best))\n",
    "#     torch.save(model,'./last_epoch.pkl')\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "model = MyModel\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 1 train epoch\n",
      "epoch 0\n",
      "735.0 1107.0\n",
      "accuracy: 0.663957\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 1\n",
      "734.0 1107.0\n",
      "accuracy: 0.663053\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 2\n",
      "734.0 1107.0\n",
      "accuracy: 0.663053\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 3\n",
      "726.0 1107.0\n",
      "accuracy: 0.655827\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 4\n",
      "723.0 1107.0\n",
      "accuracy: 0.653117\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 5\n",
      "717.0 1107.0\n",
      "accuracy: 0.647696\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 6\n",
      "694.0 1107.0\n",
      "accuracy: 0.626920\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 7\n",
      "686.0 1107.0\n",
      "accuracy: 0.619693\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 8\n",
      "688.0 1107.0\n",
      "accuracy: 0.621500\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 9\n",
      "665.0 1107.0\n",
      "accuracy: 0.600723\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 10\n",
      "672.0 1107.0\n",
      "accuracy: 0.607046\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 11\n",
      "687.0 1107.0\n",
      "accuracy: 0.620596\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 12\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 13\n",
      "664.0 1107.0\n",
      "accuracy: 0.599819\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 14\n",
      "665.0 1107.0\n",
      "accuracy: 0.600723\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 15\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 16\n",
      "643.0 1107.0\n",
      "accuracy: 0.580849\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 17\n",
      "676.0 1107.0\n",
      "accuracy: 0.610659\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 18\n",
      "654.0 1107.0\n",
      "accuracy: 0.590786\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 19\n",
      "658.0 1107.0\n",
      "accuracy: 0.594399\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 20\n",
      "658.0 1107.0\n",
      "accuracy: 0.594399\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 21\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 22\n",
      "657.0 1107.0\n",
      "accuracy: 0.593496\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 23\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 24\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 25\n",
      "664.0 1107.0\n",
      "accuracy: 0.599819\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 26\n",
      "664.0 1107.0\n",
      "accuracy: 0.599819\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 27\n",
      "658.0 1107.0\n",
      "accuracy: 0.594399\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 28\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 29\n",
      "657.0 1107.0\n",
      "accuracy: 0.593496\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 30\n",
      "664.0 1107.0\n",
      "accuracy: 0.599819\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 31\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 32\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 33\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 34\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 35\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 36\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 37\n",
      "660.0 1107.0\n",
      "accuracy: 0.596206\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 38\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 39\n",
      "664.0 1107.0\n",
      "accuracy: 0.599819\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 40\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 41\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 42\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 43\n",
      "658.0 1107.0\n",
      "accuracy: 0.594399\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 44\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 45\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 46\n",
      "660.0 1107.0\n",
      "accuracy: 0.596206\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 47\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 48\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 49\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 50\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 51\n",
      "660.0 1107.0\n",
      "accuracy: 0.596206\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 52\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 53\n",
      "660.0 1107.0\n",
      "accuracy: 0.596206\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 54\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 55\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 56\n",
      "660.0 1107.0\n",
      "accuracy: 0.596206\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 57\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 58\n",
      "660.0 1107.0\n",
      "accuracy: 0.596206\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 59\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 60\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 61\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 62\n",
      "658.0 1107.0\n",
      "accuracy: 0.594399\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 63\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 64\n",
      "658.0 1107.0\n",
      "accuracy: 0.594399\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 65\n",
      "660.0 1107.0\n",
      "accuracy: 0.596206\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 66\n",
      "657.0 1107.0\n",
      "accuracy: 0.593496\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 67\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 68\n",
      "659.0 1107.0\n",
      "accuracy: 0.595303\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 69\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 70\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 71\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 72\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 73\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 74\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 75\n",
      "660.0 1107.0\n",
      "accuracy: 0.596206\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 76\n",
      "660.0 1107.0\n",
      "accuracy: 0.596206\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 77\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 78\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 79\n",
      "664.0 1107.0\n",
      "accuracy: 0.599819\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 80\n",
      "659.0 1107.0\n",
      "accuracy: 0.595303\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 81\n",
      "660.0 1107.0\n",
      "accuracy: 0.596206\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 82\n",
      "660.0 1107.0\n",
      "accuracy: 0.596206\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 83\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 84\n",
      "660.0 1107.0\n",
      "accuracy: 0.596206\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 85\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 86\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 87\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 88\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 89\n",
      "660.0 1107.0\n",
      "accuracy: 0.596206\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 90\n",
      "660.0 1107.0\n",
      "accuracy: 0.596206\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 91\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 92\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 93\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 94\n",
      "664.0 1107.0\n",
      "accuracy: 0.599819\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 95\n",
      "659.0 1107.0\n",
      "accuracy: 0.595303\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 96\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 97\n",
      "660.0 1107.0\n",
      "accuracy: 0.596206\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 98\n",
      "660.0 1107.0\n",
      "accuracy: 0.596206\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 99\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 100\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 101\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 102\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 103\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 104\n",
      "660.0 1107.0\n",
      "accuracy: 0.596206\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 105\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 106\n",
      "660.0 1107.0\n",
      "accuracy: 0.596206\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 107\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 108\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 109\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 110\n",
      "664.0 1107.0\n",
      "accuracy: 0.599819\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 111\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 112\n",
      "664.0 1107.0\n",
      "accuracy: 0.599819\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 113\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 114\n",
      "664.0 1107.0\n",
      "accuracy: 0.599819\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 115\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 116\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 117\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 118\n",
      "664.0 1107.0\n",
      "accuracy: 0.599819\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 119\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 120\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 121\n",
      "661.0 1107.0\n",
      "accuracy: 0.597109\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 122\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 123\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 124\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 125\n",
      "662.0 1107.0\n",
      "accuracy: 0.598013\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 126\n",
      "664.0 1107.0\n",
      "accuracy: 0.599819\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 1 train epoch\n",
      "epoch 127\n",
      "665.0 1107.0\n",
      "accuracy: 0.600723\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 128\n",
      "666.0 1107.0\n",
      "accuracy: 0.601626\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 129\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 130\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 131\n",
      "663.0 1107.0\n",
      "accuracy: 0.598916\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 132\n",
      "665.0 1107.0\n",
      "accuracy: 0.600723\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 133\n",
      "665.0 1107.0\n",
      "accuracy: 0.600723\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 134\n",
      "665.0 1107.0\n",
      "accuracy: 0.600723\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 135\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 136\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 137\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 138\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 139\n",
      "666.0 1107.0\n",
      "accuracy: 0.601626\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 140\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 141\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 142\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 143\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 144\n",
      "665.0 1107.0\n",
      "accuracy: 0.600723\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 145\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 146\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 147\n",
      "666.0 1107.0\n",
      "accuracy: 0.601626\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 148\n",
      "665.0 1107.0\n",
      "accuracy: 0.600723\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 149\n",
      "666.0 1107.0\n",
      "accuracy: 0.601626\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 150\n",
      "666.0 1107.0\n",
      "accuracy: 0.601626\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 151\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 152\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 153\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 154\n",
      "664.0 1107.0\n",
      "accuracy: 0.599819\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 155\n",
      "665.0 1107.0\n",
      "accuracy: 0.600723\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 156\n",
      "665.0 1107.0\n",
      "accuracy: 0.600723\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 157\n",
      "664.0 1107.0\n",
      "accuracy: 0.599819\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 158\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 159\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 160\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 161\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 162\n",
      "666.0 1107.0\n",
      "accuracy: 0.601626\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 163\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 164\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 165\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 166\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 167\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 168\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 169\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 170\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 171\n",
      "669.0 1107.0\n",
      "accuracy: 0.604336\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 172\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 173\n",
      "666.0 1107.0\n",
      "accuracy: 0.601626\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 174\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 175\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 176\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 177\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 178\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 179\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 180\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 181\n",
      "666.0 1107.0\n",
      "accuracy: 0.601626\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 182\n",
      "666.0 1107.0\n",
      "accuracy: 0.601626\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 183\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 184\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 185\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 186\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 187\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 188\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 189\n",
      "666.0 1107.0\n",
      "accuracy: 0.601626\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 190\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 191\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 192\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 193\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 194\n",
      "669.0 1107.0\n",
      "accuracy: 0.604336\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 195\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 196\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 197\n",
      "668.0 1107.0\n",
      "accuracy: 0.603433\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 198\n",
      "669.0 1107.0\n",
      "accuracy: 0.604336\n",
      "\n",
      "finished 1 train epoch\n",
      "epoch 199\n",
      "667.0 1107.0\n",
      "accuracy: 0.602529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(model,train_loader,val_loader,criterion,optimizer,200,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.0363e-01, 1.1769e-05, 2.8642e-08, 1.0000e+00, 1.3245e-13, 2.6972e-17,\n",
      "        6.1149e-08, 9.8163e-01, 1.0000e+00, 1.3167e-01, 7.2368e-01, 1.5811e-02,\n",
      "        3.8579e-09, 9.3560e-11, 1.0000e+00, 9.9996e-01, 1.1236e-10, 1.0000e+00,\n",
      "        9.9996e-01, 1.0000e+00, 4.3980e-01, 3.8597e-01, 1.1731e-22, 9.9995e-01,\n",
      "        1.6373e-03, 1.0535e-15, 1.0000e+00, 2.9101e-08, 1.7422e-08, 4.1866e-03,\n",
      "        6.2611e-10, 6.7406e-01, 7.4260e-12, 1.0000e+00, 1.8196e-18, 7.8738e-16,\n",
      "        1.3146e-11, 7.8760e-01, 1.9414e-03, 4.0261e-01, 5.8733e-05, 2.9760e-06,\n",
      "        2.0073e-03, 2.7675e-03, 1.0000e+00, 9.8660e-01, 7.7495e-07, 7.2315e-09,\n",
      "        1.0000e+00, 8.2817e-02, 9.9956e-01, 2.7288e-24, 8.9131e-12, 1.0000e+00,\n",
      "        5.9866e-10, 1.4928e-08, 4.2155e-10, 9.4661e-13, 4.8067e-02, 2.5203e-24,\n",
      "        5.6830e-09, 1.9579e-14, 2.7072e-01, 4.4020e-06], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1], device='cuda:0')\n",
      "tensor([1.7520e-13, 6.9380e-08, 2.6090e-11, 9.9904e-01, 3.0560e-13, 1.6507e-03,\n",
      "        9.7215e-01, 1.0000e+00, 9.9923e-01, 2.6803e-04, 1.9732e-01, 6.4067e-06,\n",
      "        4.3953e-11, 1.0000e+00, 1.1179e-11, 1.2177e-08, 9.7212e-01, 1.9006e-06,\n",
      "        1.5956e-04, 9.1642e-01, 1.0000e+00, 4.2869e-08, 9.9998e-01, 1.4543e-02,\n",
      "        2.6509e-04, 1.2255e-03, 1.0000e+00, 2.3832e-04, 3.8053e-05, 5.5495e-01,\n",
      "        2.9114e-02, 1.3746e-07, 1.5311e-14, 9.9754e-01, 1.0457e-03, 5.0154e-09,\n",
      "        1.0000e+00, 1.1588e-12, 3.1998e-08, 7.0329e-13, 9.2631e-01, 1.0000e+00,\n",
      "        6.9737e-08, 9.7644e-01, 1.9601e-04, 1.0721e-05, 9.9967e-01, 1.2700e-12,\n",
      "        1.0000e+00, 8.4409e-05, 1.2231e-08, 1.0889e-04, 1.0000e+00, 2.5181e-03,\n",
      "        2.9161e-01, 4.5381e-06, 9.6404e-09, 9.0092e-01, 6.1086e-03, 1.3427e-01,\n",
      "        1.6505e-02, 2.2304e-03, 2.7707e-09, 6.5091e-11], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "tensor([1.7484e-01, 8.9978e-01, 2.5563e-06, 1.0000e+00, 2.5965e-16, 1.4501e-10,\n",
      "        1.0000e+00, 9.9960e-01, 4.9520e-05, 4.3188e-05, 1.0928e-09, 3.2946e-10,\n",
      "        1.0304e-09, 1.4293e-02, 9.4974e-10, 2.2653e-08, 9.9986e-01, 6.5712e-11,\n",
      "        2.4918e-06, 9.1913e-03, 1.0000e+00, 9.9388e-01, 2.1404e-05, 3.1462e-09,\n",
      "        6.5508e-09, 3.5727e-18, 7.8501e-15, 2.5519e-11, 4.4638e-01, 4.2999e-03,\n",
      "        1.4237e-12, 1.6564e-08, 7.0278e-06, 1.9235e-02, 1.6432e-26, 3.9842e-07,\n",
      "        2.5315e-05, 9.9916e-01, 4.1946e-19, 6.1991e-09, 6.6228e-11, 1.6451e-05,\n",
      "        1.0218e-01, 1.0000e+00, 9.4665e-01, 3.0173e-02, 6.0654e-03, 1.0000e+00,\n",
      "        1.0808e-06, 1.0000e+00, 4.8453e-12, 1.7368e-02, 3.2382e-08, 1.0000e+00,\n",
      "        9.4722e-01, 1.0000e+00, 1.0000e+00, 4.5806e-04, 1.0251e-12, 3.0144e-13,\n",
      "        9.9999e-01, 9.9983e-01, 9.9974e-01, 2.5943e-10], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([1.2125e-12, 9.7452e-01, 1.0000e+00, 1.8448e-01, 7.1398e-01, 9.9936e-01,\n",
      "        9.0027e-01, 5.1371e-06, 1.1034e-07, 3.7101e-01, 3.6101e-02, 8.8017e-01,\n",
      "        1.3099e-11, 1.0000e+00, 4.3235e-11, 1.6099e-19, 3.6969e-04, 3.1955e-06,\n",
      "        9.9060e-01, 4.6673e-10, 2.0616e-26, 9.9995e-01, 1.6217e-01, 9.9994e-01,\n",
      "        2.0782e-07, 9.9780e-01, 8.2097e-24, 2.2936e-07, 9.3981e-01, 7.8015e-01,\n",
      "        9.9951e-01, 2.1724e-03, 9.6550e-02, 1.8156e-06, 1.4033e-02, 9.9992e-01,\n",
      "        2.0859e-06, 8.5611e-01, 9.9999e-01, 1.6531e-11, 9.9989e-01, 7.9254e-10,\n",
      "        3.8341e-09, 3.4903e-08, 9.9998e-01, 1.1791e-04, 7.1997e-02, 1.0000e+00,\n",
      "        1.9928e-16, 4.9843e-03, 9.4860e-03, 9.9929e-01, 9.9457e-01, 1.1138e-05,\n",
      "        2.5772e-23, 7.5589e-15, 9.6707e-01, 1.1853e-06, 1.1050e-10, 1.0511e-05,\n",
      "        9.0285e-01, 4.8341e-19, 1.0000e+00, 1.5905e-05], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([9.9895e-01, 6.7053e-05, 1.7741e-03, 1.1883e-01, 1.0349e-05, 5.2494e-17,\n",
      "        6.2228e-02, 2.1534e-05, 3.5751e-15, 9.8616e-01, 1.6969e-02, 9.4512e-01,\n",
      "        2.3168e-09, 2.3900e-03, 8.7485e-01, 1.0220e-17, 1.0000e+00, 2.0123e-01,\n",
      "        9.9990e-01, 2.4362e-04, 9.9829e-01, 8.9660e-04, 5.0259e-16, 1.1995e-06,\n",
      "        9.8577e-01, 9.9999e-01, 1.4127e-04, 2.0945e-03, 6.8501e-02, 1.0000e+00,\n",
      "        3.5582e-01, 1.4824e-04, 9.7997e-01, 1.0000e+00, 6.5098e-04, 9.9995e-01,\n",
      "        4.1453e-32, 4.7152e-16, 9.2789e-01, 9.9405e-01, 1.7586e-10, 7.2377e-01,\n",
      "        8.3897e-12, 9.8623e-01, 4.2354e-06, 4.0166e-05, 8.1663e-06, 8.6141e-06,\n",
      "        7.3853e-09, 2.1727e-10, 6.0780e-06, 2.2205e-01, 1.0517e-08, 6.2345e-09,\n",
      "        4.4994e-06, 1.1315e-03, 9.9937e-01, 1.3425e-09, 9.9999e-01, 1.0000e+00,\n",
      "        3.3946e-15, 1.0000e+00, 1.0209e-10, 2.0758e-18], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "tensor([9.9338e-01, 9.8862e-05, 9.0219e-03, 3.5172e-12, 9.9920e-01, 7.1387e-06,\n",
      "        2.3752e-03, 6.7635e-02, 4.5629e-04, 7.3600e-04, 2.7275e-01, 9.1529e-06,\n",
      "        9.9976e-01, 8.0350e-01, 1.7772e-13, 9.9672e-01, 9.9999e-01, 1.5195e-02,\n",
      "        4.8322e-07, 2.0842e-01, 8.2243e-09, 2.5287e-12, 1.0000e+00, 4.9033e-02,\n",
      "        3.2858e-04, 1.0000e+00, 9.9950e-01, 9.9993e-01, 1.8801e-05, 9.9999e-01,\n",
      "        3.0889e-12, 1.4187e-06, 1.0000e+00, 1.6246e-06, 4.4832e-14, 9.9879e-01,\n",
      "        1.0000e+00, 2.1266e-01, 9.0789e-01, 1.1583e-15, 4.2273e-02, 5.4473e-05,\n",
      "        2.5759e-06, 9.2306e-10, 1.1959e-08, 8.7469e-13, 9.9995e-01, 7.3879e-04,\n",
      "        1.9617e-09, 7.9498e-03, 2.6505e-02, 4.7685e-04, 3.3433e-03, 6.3897e-01,\n",
      "        3.5386e-03, 6.6459e-07, 9.7427e-18, 4.4137e-06, 3.5151e-03, 7.3011e-09,\n",
      "        4.0460e-02, 9.9937e-01, 1.8326e-08, 8.4239e-10], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "tensor([9.2321e-01, 1.0000e+00, 2.9786e-03, 3.9782e-07, 9.9992e-01, 9.3214e-01,\n",
      "        6.4878e-05, 9.3815e-03, 1.0000e+00, 5.4249e-05, 4.2132e-10, 9.7737e-01,\n",
      "        1.0277e-07, 9.9999e-01, 9.9992e-01, 1.4325e-05, 2.8330e-12, 3.8895e-04,\n",
      "        1.1446e-10, 2.3051e-01, 9.9617e-01, 2.8983e-05, 1.9583e-02, 4.7708e-02,\n",
      "        9.4706e-02, 5.2989e-02, 1.1161e-02, 9.0730e-06, 4.6765e-04, 9.9999e-01,\n",
      "        9.9881e-01, 5.3338e-13, 2.1291e-08, 7.4088e-01, 1.9802e-08, 4.0536e-03,\n",
      "        1.0918e-08, 2.3782e-10, 3.9488e-08, 7.7687e-06, 3.8865e-01, 9.9014e-01,\n",
      "        1.0841e-06, 1.0000e+00, 9.7086e-01, 2.2418e-02, 1.7203e-05, 5.4523e-07,\n",
      "        1.9346e-01, 1.1561e-02, 7.4820e-06, 7.5449e-06, 1.0000e+00, 3.4894e-19,\n",
      "        9.9542e-01, 9.9997e-01, 9.9988e-01, 2.8932e-09, 5.9431e-01, 9.6008e-08,\n",
      "        4.1570e-05, 2.5920e-09, 1.0000e+00, 1.3339e-10], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "tensor([7.7925e-06, 9.8456e-01, 1.0000e+00, 1.8322e-03, 6.6813e-01, 3.0864e-12,\n",
      "        1.0000e+00, 2.4568e-06, 1.6327e-16, 3.6879e-01, 5.5304e-09, 9.9987e-01,\n",
      "        1.7160e-04, 1.9641e-10, 9.9990e-01, 2.6751e-05, 8.3586e-10, 3.9238e-06,\n",
      "        8.8679e-01, 2.1043e-02, 2.5842e-02, 2.4569e-20, 1.1095e-07, 4.4952e-10,\n",
      "        5.8003e-09, 9.9996e-01, 9.7117e-01, 1.0000e+00, 8.9453e-07, 2.9336e-21,\n",
      "        1.0000e+00, 5.5130e-04, 3.5814e-16, 9.3909e-05, 3.5066e-02, 9.9870e-01,\n",
      "        1.9682e-03, 9.9987e-01, 3.0777e-19, 9.3904e-01, 2.8634e-05, 1.0000e+00,\n",
      "        1.0000e+00, 8.5701e-03, 1.6331e-02, 4.0184e-07, 1.4689e-12, 4.6081e-12,\n",
      "        9.7776e-01, 5.2525e-07, 2.2639e-04, 1.0916e-06, 5.7108e-04, 1.0210e-05,\n",
      "        3.4983e-03, 1.4454e-16, 1.9830e-09, 5.7836e-04, 1.2543e-06, 9.9998e-01,\n",
      "        3.8787e-06, 3.0013e-11, 1.0000e+00, 1.3567e-06], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "tensor([1.5140e-08, 1.0000e+00, 9.7949e-01, 3.0645e-03, 8.9559e-08, 2.0691e-12,\n",
      "        1.7419e-02, 1.2291e-02, 3.5222e-01, 7.7069e-12, 1.5238e-08, 1.4450e-10,\n",
      "        1.0000e+00, 2.6917e-05, 1.0000e+00, 1.8199e-21, 8.9072e-12, 3.5036e-05,\n",
      "        9.9805e-01, 5.4587e-01, 3.9758e-02, 3.5337e-05, 2.0459e-02, 1.0000e+00,\n",
      "        7.5158e-01, 2.9897e-04, 1.7725e-07, 9.9993e-01, 1.2871e-10, 2.2604e-01,\n",
      "        2.5441e-01, 3.6342e-02, 9.9980e-01, 5.9598e-08, 1.7319e-09, 5.0529e-01,\n",
      "        1.8736e-03, 1.1137e-11, 3.9623e-05, 4.0080e-09, 9.7931e-10, 3.7048e-06,\n",
      "        1.5578e-01, 3.6933e-04, 9.9995e-01, 2.2825e-05, 1.3740e-11, 7.2148e-04,\n",
      "        9.0602e-02, 6.0615e-03, 2.9661e-02, 9.1125e-01, 1.9726e-06, 1.1416e-12,\n",
      "        1.0000e+00, 2.6516e-03, 6.4864e-11, 7.5741e-09, 2.6633e-01, 9.3259e-01,\n",
      "        2.5190e-18, 9.9631e-04, 9.9554e-01, 8.1137e-09], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "tensor([9.9999e-01, 9.9509e-01, 1.4790e-02, 7.1686e-02, 1.0000e+00, 7.3490e-02,\n",
      "        4.5910e-01, 1.1352e-17, 1.3948e-10, 4.0677e-07, 1.0000e+00, 1.0000e+00,\n",
      "        1.3278e-08, 1.5311e-29, 8.8842e-03, 9.9998e-01, 5.5624e-07, 7.3052e-01,\n",
      "        1.0000e+00, 4.5888e-05, 1.0000e+00, 1.6371e-20, 2.7649e-05, 1.1667e-14,\n",
      "        1.0000e+00, 1.1854e-02, 2.6567e-10, 9.9847e-01, 1.9984e-06, 9.8936e-02,\n",
      "        2.9323e-18, 9.7957e-01, 6.9325e-03, 5.4909e-05, 9.9945e-01, 9.9999e-01,\n",
      "        9.9900e-01, 8.0262e-13, 4.8497e-13, 2.7378e-05, 4.4659e-06, 1.8256e-12,\n",
      "        8.4064e-01, 9.9999e-01, 1.4212e-06, 1.2695e-04, 1.8609e-05, 1.3973e-07,\n",
      "        9.1664e-06, 3.7559e-06, 2.8384e-08, 5.2375e-07, 6.6710e-01, 9.3933e-01,\n",
      "        8.1408e-02, 1.0000e+00, 9.9427e-01, 3.0618e-17, 5.5078e-09, 9.2780e-01,\n",
      "        5.9654e-07, 2.0248e-02, 7.3376e-09, 4.1627e-04], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([8.3727e-01, 1.1270e-09, 2.1648e-03, 5.2937e-09, 8.1233e-08, 2.5270e-07,\n",
      "        2.0543e-09, 9.9995e-01, 9.9999e-01, 9.8236e-01, 1.8897e-13, 1.0000e+00,\n",
      "        2.5979e-12, 1.0000e+00, 1.0905e-03, 9.9885e-18, 9.3005e-01, 1.0000e+00,\n",
      "        6.0130e-09, 1.7482e-05, 1.5758e-07, 1.2017e-03, 5.1330e-06, 1.9159e-13,\n",
      "        1.6177e-06, 1.0431e-11, 3.6648e-05, 4.9568e-02, 9.9246e-01, 9.9844e-01,\n",
      "        1.0516e-08, 4.3038e-04, 1.3866e-11, 4.8592e-01, 9.9855e-01, 1.0000e+00,\n",
      "        9.9335e-01, 5.7312e-25, 4.9441e-08, 9.9394e-01, 9.9603e-01, 9.8905e-01,\n",
      "        4.0849e-03, 1.1374e-06, 7.0747e-01, 5.2915e-08, 1.3622e-06, 1.0000e+00,\n",
      "        9.9818e-01, 8.0173e-09, 9.9998e-01, 7.2501e-09, 2.0320e-11, 1.5585e-16,\n",
      "        5.4915e-13, 6.0691e-01, 9.9989e-01, 1.3625e-10, 6.2886e-01, 6.6146e-10,\n",
      "        1.2327e-04, 1.4122e-10, 3.0011e-03, 7.6729e-18], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "tensor([1.4886e-09, 3.4568e-02, 1.3273e-01, 3.4492e-01, 2.4484e-24, 9.9927e-01,\n",
      "        1.0000e+00, 9.9998e-01, 1.0000e+00, 4.7568e-03, 3.3727e-01, 4.0538e-03,\n",
      "        7.1576e-01, 1.0000e+00, 9.9054e-05, 3.1156e-05, 9.9980e-01, 1.0000e+00,\n",
      "        3.0238e-04, 3.2508e-04, 1.6136e-10, 8.5526e-05, 9.9998e-01, 8.5560e-12,\n",
      "        8.2276e-19, 1.2843e-09, 4.0090e-01, 9.8705e-06, 9.3181e-01, 9.9790e-01,\n",
      "        2.4982e-03, 1.0000e+00, 9.4396e-01, 2.8894e-11, 1.0000e+00, 9.9106e-01,\n",
      "        3.4901e-02, 2.4643e-03, 6.9911e-02, 1.4613e-04, 1.2646e-07, 9.9303e-01,\n",
      "        3.2160e-11, 3.0013e-08, 7.9909e-13, 1.8935e-01, 7.6858e-11, 4.5578e-14,\n",
      "        2.2747e-10, 1.6918e-16, 5.3036e-01, 4.7739e-03, 9.9997e-01, 3.1996e-07,\n",
      "        4.5676e-07, 6.9345e-04, 5.2235e-04, 9.9977e-01, 3.7347e-03, 1.0000e+00,\n",
      "        8.9806e-01, 6.1952e-02, 1.5146e-04, 3.4238e-01], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "tensor([1.0000e+00, 8.4576e-01, 2.0458e-01, 2.4052e-01, 1.0216e-06, 1.3307e-02,\n",
      "        1.0419e-15, 9.9272e-01, 3.2566e-06, 7.4781e-18, 1.0911e-20, 2.5113e-05,\n",
      "        6.8377e-03, 9.9880e-01, 4.0162e-07, 4.4509e-01, 9.9907e-01, 1.0693e-04,\n",
      "        9.4478e-08, 1.0511e-13, 5.0862e-01, 1.9626e-08, 2.8412e-10, 2.3734e-14,\n",
      "        1.0000e+00, 2.9571e-09, 6.3565e-01, 5.6769e-05, 6.2672e-10, 5.4055e-08,\n",
      "        7.9980e-08, 3.5941e-08, 9.9415e-01, 1.8849e-10, 3.7699e-05, 3.1163e-08,\n",
      "        1.4068e-07, 2.0955e-18, 2.8680e-05, 1.0857e-04, 1.0000e+00, 4.6352e-17,\n",
      "        9.9999e-01, 3.0842e-05, 4.9427e-03, 1.4607e-10, 3.6334e-04, 2.9048e-09,\n",
      "        1.0000e+00, 1.8747e-04, 1.0000e+00, 5.7583e-07, 8.5219e-08, 9.5623e-04,\n",
      "        5.9029e-04, 5.6585e-01, 6.9513e-09, 3.0243e-09, 7.2996e-06, 1.3872e-11,\n",
      "        1.0083e-03, 1.4963e-01, 8.0891e-03, 8.6222e-01], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([1.9771e-14, 4.7558e-13, 4.0481e-09, 4.6592e-05, 2.0676e-04, 4.4647e-04,\n",
      "        1.6681e-06, 1.2798e-07, 1.0000e+00, 8.4587e-03, 9.9998e-01, 9.7032e-09,\n",
      "        7.9182e-03, 1.0000e+00, 5.4854e-08, 3.8852e-07, 9.9997e-01, 4.3384e-06,\n",
      "        9.9706e-01, 9.9940e-01, 1.2400e-05, 1.4543e-03, 1.2792e-01, 6.5155e-12,\n",
      "        1.0000e+00, 9.1731e-01, 5.9278e-02, 3.5843e-01, 9.9999e-01, 6.1456e-07,\n",
      "        2.2640e-02, 1.2611e-12, 3.0669e-06, 1.0000e+00, 9.3939e-01, 5.2031e-10,\n",
      "        1.0000e+00, 7.3584e-01, 4.5404e-04, 1.0000e+00, 9.9874e-01, 1.0000e+00,\n",
      "        5.4965e-01, 5.4524e-01, 5.4456e-06, 2.2123e-15, 1.1680e-06, 9.9999e-01,\n",
      "        1.0570e-03, 1.0000e+00, 3.4558e-04, 2.2029e-03, 7.4828e-01, 9.9844e-01,\n",
      "        8.1479e-01, 4.6859e-09, 1.0046e-04, 5.9066e-01, 5.6812e-02, 4.5621e-17,\n",
      "        7.4371e-01, 2.6454e-05, 9.9999e-01, 3.3264e-04], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "tensor([9.1048e-01, 9.4704e-01, 9.9997e-01, 2.2962e-09, 9.9433e-01, 5.9154e-01,\n",
      "        6.3622e-12, 2.4266e-01, 1.0000e+00, 7.0770e-05, 4.1411e-07, 1.5948e-02,\n",
      "        9.9995e-01, 4.1484e-06, 9.4812e-09, 1.0000e+00, 1.1276e-19, 2.6308e-03,\n",
      "        2.2346e-07, 9.9930e-01, 9.9996e-01, 2.7955e-04, 1.3164e-12, 3.9797e-03,\n",
      "        2.4360e-12, 2.9841e-14, 2.9227e-07, 8.7899e-01, 3.7321e-01, 1.0000e+00,\n",
      "        1.4779e-02, 1.9229e-08, 9.8650e-01, 8.8012e-01, 2.9903e-06, 3.2620e-07,\n",
      "        1.1096e-16, 1.0000e+00, 1.2098e-01, 9.9992e-01, 1.0000e+00, 3.2633e-01,\n",
      "        6.6553e-10, 2.1090e-04, 9.6913e-01, 7.1046e-11, 9.5524e-01, 1.4075e-05,\n",
      "        1.0000e+00, 5.3986e-07, 5.6858e-06, 4.2308e-01, 1.9260e-10, 1.4049e-03,\n",
      "        2.9478e-06, 8.5890e-05, 8.1649e-08, 1.3407e-08, 4.8968e-05, 9.9931e-01,\n",
      "        1.3570e-07, 1.7557e-10, 9.9622e-01, 1.1424e-07], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0], device='cuda:0')\n",
      "tensor([2.2335e-05, 2.2074e-14, 9.9894e-01, 4.5856e-08, 2.3101e-05, 8.9982e-03,\n",
      "        2.7857e-02, 1.0000e+00, 9.1019e-01, 1.4230e-25, 1.9866e-05, 9.9423e-01,\n",
      "        8.6402e-01, 9.8533e-08, 7.0990e-09, 8.6535e-01, 1.9247e-14, 1.0000e+00,\n",
      "        4.9220e-04, 6.2362e-01, 1.8159e-14, 1.7529e-12, 1.0000e+00, 2.0723e-05,\n",
      "        2.6940e-10, 1.0000e+00, 9.9989e-01, 9.4767e-06, 8.7968e-03, 4.2513e-05,\n",
      "        9.9999e-01, 2.5118e-16, 1.3847e-09, 1.3631e-02, 1.0000e+00, 1.0000e+00,\n",
      "        8.7907e-01, 1.4583e-05, 2.4010e-03, 9.9749e-01, 1.2183e-11, 7.6690e-03,\n",
      "        2.3900e-12, 5.1532e-12, 8.2450e-04, 9.9887e-01, 1.0000e+00, 1.0000e+00,\n",
      "        8.1244e-01, 1.1572e-17, 1.1492e-03, 1.6043e-12, 9.7568e-01, 1.5293e-05,\n",
      "        2.7215e-14, 1.4141e-11, 2.0532e-16, 1.0000e+00, 8.5019e-11, 6.7761e-11,\n",
      "        5.5631e-03, 1.8130e-06, 1.0000e+00, 2.3926e-06], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "tensor([1.8172e-06, 1.6087e-05, 9.7728e-03, 3.0782e-05, 7.0182e-01, 9.6473e-01,\n",
      "        9.9963e-01, 2.0790e-04, 4.9145e-06, 7.5721e-14, 7.9664e-03, 1.3072e-08,\n",
      "        1.4379e-18, 1.5032e-06, 2.1954e-04, 1.0179e-10, 9.9913e-01, 1.0000e+00,\n",
      "        1.0000e+00, 2.4857e-06, 5.9951e-04, 1.9098e-08, 9.9999e-01, 1.1420e-25,\n",
      "        1.0000e+00, 8.7580e-05, 9.9669e-01, 4.8981e-01, 1.0046e-01, 7.4312e-01,\n",
      "        5.3661e-02, 3.8547e-04, 1.0000e+00, 4.2386e-04, 3.4726e-09, 3.9273e-14,\n",
      "        1.0000e+00, 1.0000e+00, 9.9994e-01, 6.9786e-12, 5.6302e-05, 6.6040e-05,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 4.9588e-04, 6.4899e-08, 1.3806e-11,\n",
      "        4.8983e-11, 1.1550e-14, 9.5926e-03, 2.9781e-07, 9.5414e-02, 8.2389e-01,\n",
      "        9.3384e-01, 4.5756e-10, 3.1571e-08, 9.9989e-01, 4.2730e-05, 9.5031e-01,\n",
      "        1.9116e-01, 9.6670e-01, 9.9995e-01, 7.8971e-08], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "tensor([0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "tensor([3.8486e-16, 7.1026e-08, 5.9184e-04, 1.9465e-12, 1.1401e-02, 4.1601e-05,\n",
      "        1.0000e+00, 1.9400e-07, 1.0000e+00, 1.0000e+00, 1.9155e-02, 8.4806e-01,\n",
      "        9.9857e-01, 1.0000e+00, 9.9985e-01, 8.2677e-02, 1.0000e+00, 4.7944e-15,\n",
      "        1.0000e+00], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
      "tensor([1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1],\n",
      "       device='cuda:0')\n",
      "664.0 1107.0\n",
      "accuracy: 0.599819\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5998193315266486"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model,val_loader,device,show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3347790729194904"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].sum()/3689"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.375495e-02,  1.222110e-03,  7.253284e-02,  1.930000e+02,\n",
       "         2.570000e+02,  5.142023e-03,  4.413058e-06,  4.049791e-03,\n",
       "         4.490844e-05,  6.731100e-03,  5.514662e+00,  4.483424e+01,\n",
       "        -1.208101e+00, -2.961012e+01,  2.840202e+01,  4.040000e+02,\n",
       "         1.930000e+02, -1.001011e+01,  1.116773e-02, -1.277413e+01,\n",
       "         1.781583e+01,  4.513614e+00, -1.168356e+00,  5.066848e+00,\n",
       "         5.941076e+00, -1.710257e+01,  2.304364e+01,  6.400000e+01,\n",
       "         3.110000e+02, -3.466938e+00, -1.350412e-02, -1.246681e-01,\n",
       "         1.319619e+01,  4.115194e+00, -7.652906e-01,  3.820773e+00,\n",
       "         1.214566e+01, -1.795498e+01,  3.010064e+01,  3.830000e+02,\n",
       "         3.060000e+02, -3.996887e+00, -1.041718e-02, -1.418636e+00,\n",
       "         3.018254e+01,  5.692740e+00,  1.423583e-01,  2.692385e+00,\n",
       "         7.340120e+00, -2.195029e+01,  2.929041e+01,  2.700000e+02,\n",
       "         3.250000e+02, -5.176172e+00, -1.876240e-02, -5.324774e-01,\n",
       "         2.430781e+01,  5.614697e+00, -6.989497e-01,  3.350750e+00,\n",
       "         7.709482e+00, -2.086652e+01,  2.857600e+01,  3.070000e+02,\n",
       "         3.870000e+02, -1.849226e+00, -7.561879e-03,  2.233910e-02,\n",
       "         2.616947e+01,  5.228936e+00, -8.126289e-01,  3.912256e+00,\n",
       "         1.514483e+01, -1.265102e+01,  2.779585e+01,  2.050000e+02,\n",
       "         4.920000e+02,  1.937735e+00, -6.361698e-03,  3.512255e+00,\n",
       "         2.965316e+01,  5.521129e+00, -1.382618e-01,  2.743822e+00,\n",
       "         1.461641e+01, -1.725070e+01,  3.186711e+01,  1.600000e+02,\n",
       "         4.010000e+02, -1.564716e+00, -4.529279e-03, -4.437198e-01,\n",
       "         2.159105e+01,  4.691655e+00, -3.696783e-01,  3.561299e+00,\n",
       "         8.978169e+00, -2.341773e+01,  3.239590e+01,  6.700000e+01,\n",
       "         1.650000e+02, -2.998475e+00, -4.195278e-03, -1.960143e+00,\n",
       "         3.224591e+01,  5.710231e+00, -8.155295e-01,  3.797428e+00,\n",
       "         1.113478e+01, -1.561419e+01,  2.674897e+01,  4.860000e+02,\n",
       "         4.190000e+02, -2.151324e+00, -2.980231e-03, -1.413716e+00,\n",
       "         2.548630e+01,  5.066398e+00, -2.336229e-01,  2.767661e+00,\n",
       "         1.377794e+01, -1.917523e+01,  3.295316e+01,  3.140000e+02,\n",
       "         2.870000e+02, -9.004529e-01, -7.458563e-04, -7.158535e-01,\n",
       "         1.806626e+01,  4.251783e+00, -3.756078e-01,  4.327522e+00,\n",
       "         1.228087e+01, -1.130980e+01,  2.359067e+01,  3.150000e+02,\n",
       "         1.860000e+02, -1.538318e+00, -2.096096e-03, -1.019534e+00,\n",
       "         1.240305e+01,  3.534562e+00,  4.807863e-01,  4.026908e+00,\n",
       "         1.308278e+01, -1.880326e+01,  3.188604e+01,  3.170000e+02,\n",
       "         4.040000e+02,  7.288738e-02, -3.589335e-03,  9.612477e-01,\n",
       "         1.673870e+01,  4.123448e+00, -4.297178e-01,  4.781847e+00,\n",
       "         1.925053e-01,  1.359927e-02,  1.789060e-01,  1.940000e+02,\n",
       "         4.180000e+02,  6.854595e-02, -7.791457e-05,  8.782981e-02,\n",
       "         1.069510e-03,  3.455382e-02,  9.861062e-01,  3.642406e+00,\n",
       "         8.790712e-01,  1.013249e-01,  7.777463e-01,  3.050000e+02,\n",
       "         4.600000e+01,  2.698705e-01,  4.263823e-04,  1.643409e-01,\n",
       "         1.969620e-02,  1.530470e-01,  1.600111e+00,  5.856485e+00,\n",
       "         4.735675e+02,  0.000000e+00,  4.735675e+02,  3.130000e+02,\n",
       "         0.000000e+00,  2.559649e+01,  5.986399e-02,  1.078015e+01,\n",
       "         8.853338e+03,  9.448179e+01,  3.767384e+00,  1.605428e+01,\n",
       "         1.818878e-02, -1.109961e-02,  2.928839e-02,  1.910000e+02,\n",
       "         1.950000e+02,  1.597670e-05,  1.265387e-08,  1.284487e-05,\n",
       "         3.189708e-06,  1.785976e-03,  3.356005e+00,  4.395309e+01,\n",
       "         2.684534e+00, -4.600863e+00,  7.285397e+00,  6.600000e+01,\n",
       "         1.910000e+02,  1.183724e-02,  1.918971e-04, -3.565730e-02,\n",
       "         6.589637e-01,  8.122306e-01, -1.429987e+00,  9.109556e+00,\n",
       "         2.818734e+00, -2.570065e+00,  5.388799e+00,  4.080000e+02,\n",
       "         4.020000e+02, -1.505093e-02,  6.398333e-05, -3.088680e-02,\n",
       "         5.652950e-01,  7.519168e-01, -3.787550e-02,  4.441031e+00,\n",
       "         3.856813e+00, -3.182052e+00,  7.038865e+00,  3.780000e+02,\n",
       "         4.790000e+02, -9.026032e-03, -3.183302e-05, -1.147359e-03,\n",
       "         1.004194e+00,  1.002105e+00,  3.791418e-01,  5.226896e+00,\n",
       "         2.644496e+00, -3.277575e+00,  5.922071e+00,  4.870000e+02,\n",
       "         3.990000e+02, -1.298503e-02,  5.647284e-05, -2.696205e-02,\n",
       "         6.546265e-01,  8.091304e-01, -2.246251e-01,  3.603084e+00,\n",
       "         3.203760e+00, -4.957456e+00,  8.161216e+00,  2.000000e+02,\n",
       "         1.590000e+02, -1.183556e-02, -1.904263e-04,  3.529495e-02,\n",
       "         1.343022e+00,  1.159209e+00, -6.928526e-01,  5.262748e+00,\n",
       "         4.370290e+00, -5.721473e+00,  1.009176e+01,  1.790000e+02,\n",
       "         3.560000e+02, -1.443837e-02, -3.457639e-04,  7.113819e-02,\n",
       "         1.626451e+00,  1.276285e+00, -2.247293e-01,  4.801866e+00,\n",
       "         4.756456e+00, -4.364777e+00,  9.121233e+00,  1.580000e+02,\n",
       "         1.760000e+02, -8.159724e-03,  2.175987e-05, -1.354529e-02,\n",
       "         1.357653e+00,  1.165188e+00, -9.780435e-02,  4.349313e+00,\n",
       "         5.451556e+00, -5.696927e+00,  1.114848e+01,  1.910000e+02,\n",
       "         1.950000e+02, -4.337829e-03,  1.323106e-04, -3.708469e-02,\n",
       "         2.051811e+00,  1.432540e+00, -2.435201e-01,  4.179462e+00,\n",
       "         2.995821e+00, -3.293037e+00,  6.288858e+00,  1.960000e+02,\n",
       "         1.030000e+02,  7.343621e-03,  2.158407e-04, -4.607695e-02,\n",
       "         1.396861e+00,  1.182293e+00, -1.545185e-01,  2.882682e+00,\n",
       "         4.127014e+00, -3.660989e+00,  7.788003e+00,  3.810000e+02,\n",
       "         2.860000e+02,  8.793660e-03,  1.087405e-04, -1.811962e-02,\n",
       "         1.304407e+00,  1.142212e+00, -7.507315e-02,  3.389015e+00,\n",
       "         3.049749e+00, -4.214861e+00,  7.264610e+00,  3.070000e+02,\n",
       "         3.210000e+02,  8.774853e-03, -1.135038e-04,  3.686703e-02,\n",
       "         1.303457e+00,  1.141806e+00, -1.871759e-01,  3.101550e+00,\n",
       "         3.243124e+00, -4.934044e+00,  8.177168e+00,  4.080000e+02,\n",
       "         4.020000e+02, -6.722861e-04, -1.763787e-04,  4.298145e-02,\n",
       "         1.368462e+00,  1.170085e+00, -3.726720e-01,  3.984680e+00,\n",
       "         3.097613e-02, -2.840737e-02,  5.938350e-02,  6.100000e+01,\n",
       "         6.600000e+01, -6.263466e-05, -1.285510e-06,  2.555291e-04,\n",
       "         4.161487e-05,  6.453584e-03,  4.799408e-01,  7.618273e+00,\n",
       "         1.671309e-01, -1.687988e-01,  3.359297e-01,  3.010000e+02,\n",
       "         2.720000e+02,  4.678573e-04, -1.873195e-06,  9.314731e-04,\n",
       "         1.181656e-03,  3.437627e-02,  4.754415e-01,  8.428472e+00,\n",
       "         1.259202e+02, -1.257519e+02,  2.516721e+02,  2.690000e+02,\n",
       "         2.730000e+02, -3.977649e-08, -1.248533e-03,  3.090118e-01,\n",
       "         6.207707e+02,  2.491591e+01, -2.651426e-01,  1.668853e+01],\n",
       "       [ 6.153475e-02,  1.219221e-03,  6.031553e-02,  1.900000e+02,\n",
       "         3.130000e+02,  5.570916e-03,  1.438495e-05,  2.729889e-03,\n",
       "         6.386769e-05,  8.159153e-03,  3.605069e+00,  1.831266e+01,\n",
       "        -1.029650e+00, -2.965730e+01,  2.862765e+01,  3.850000e+02,\n",
       "         1.900000e+02, -1.003229e+01,  6.106234e-03, -1.123827e+01,\n",
       "         2.242255e+01,  4.786419e+00, -1.292251e+00,  5.157386e+00,\n",
       "         3.168628e+00, -1.658874e+01,  1.975737e+01,  1.130000e+02,\n",
       "         3.920000e+02, -2.819629e+00, -1.154210e-02, -5.400638e-01,\n",
       "         9.948921e+00,  3.419039e+00, -1.075326e+00,  4.580153e+00,\n",
       "         1.169424e+01, -1.849591e+01,  3.019015e+01,  1.900000e+02,\n",
       "         3.330000e+02, -3.205200e+00, -9.818858e-03, -1.265975e+00,\n",
       "         2.771278e+01,  5.382625e+00, -2.390076e-01,  2.953752e+00,\n",
       "         5.613528e+00, -2.498552e+01,  3.059905e+01,  4.200000e+01,\n",
       "         3.340000e+02, -3.438718e+00, -3.129038e-02,  2.741132e+00,\n",
       "         2.205585e+01,  5.903430e+00, -1.736370e+00,  6.023233e+00,\n",
       "         8.396878e+00, -1.465469e+01,  2.305156e+01,  1.670000e+02,\n",
       "         2.200000e+02, -1.425488e+00, -8.611561e-03,  2.752947e-01,\n",
       "         1.927534e+01,  4.499382e+00, -5.139129e-01,  2.906955e+00,\n",
       "         1.249186e+01, -1.496865e+01,  2.746051e+01,  3.500000e+02,\n",
       "         2.180000e+02,  1.853201e+00,  4.912966e-03,  8.828903e-01,\n",
       "         1.261761e+01,  3.596252e+00, -8.598781e-01,  6.511739e+00,\n",
       "         1.807728e+01, -1.251326e+01,  3.059055e+01,  2.220000e+02,\n",
       "         1.370000e+02,  9.675846e-01,  8.523075e-03, -7.157227e-01,\n",
       "         2.598650e+01,  5.189970e+00,  8.578282e-01,  4.440847e+00,\n",
       "         1.356460e+01, -2.197302e+01,  3.553762e+01,  2.480000e+02,\n",
       "         2.270000e+02, -1.954393e+00,  9.888955e-03, -3.907462e+00,\n",
       "         4.192451e+01,  6.572856e+00, -8.450168e-01,  3.953038e+00,\n",
       "         1.342722e+01, -2.085317e+01,  3.428038e+01,  3.880000e+02,\n",
       "         2.480000e+02, -3.009814e+00, -9.084356e-04, -2.830398e+00,\n",
       "         2.465627e+01,  4.966593e+00, -4.559504e-01,  4.474975e+00,\n",
       "         1.020492e+01, -8.528571e+00,  1.873349e+01,  2.460000e+02,\n",
       "         2.260000e+02,  5.700355e-01,  6.122209e-03, -6.391007e-01,\n",
       "         1.226232e+01,  3.571011e+00,  1.613393e-01,  2.700802e+00,\n",
       "         6.293916e+00, -1.448496e+01,  2.077888e+01,  1.390000e+02,\n",
       "         1.890000e+02, -8.921632e-01, -3.997647e-03, -1.026279e-01,\n",
       "         1.156765e+01,  3.431690e+00, -6.754006e-01,  3.866830e+00,\n",
       "         9.315955e+00, -1.490013e+01,  2.421609e+01,  1.910000e+02,\n",
       "         3.360000e+02, -1.281013e+00, -1.710243e-02,  2.096717e+00,\n",
       "         1.494871e+01,  4.332550e+00, -4.800946e-01,  3.411799e+00,\n",
       "         1.758839e-01,  2.387428e-02,  1.520097e-01,  2.490000e+02,\n",
       "         3.850000e+02,  6.834055e-02, -1.608831e-05,  7.151800e-02,\n",
       "         1.021336e-03,  3.201122e-02,  1.219731e+00,  3.852304e+00,\n",
       "         8.931246e-01,  1.115830e-01,  7.815416e-01,  3.310000e+02,\n",
       "         3.600000e+01,  2.459787e-01,  7.529208e-04,  9.727685e-02,\n",
       "         1.659283e-02,  1.549222e-01,  2.025142e+00,  7.416374e+00,\n",
       "         4.005215e+02,  0.000000e+00,  4.005215e+02,  3.290000e+02,\n",
       "         0.000000e+00,  1.770451e+01,  1.817383e-01, -1.818880e+01,\n",
       "         5.029733e+03,  7.390095e+01,  4.228710e+00,  1.971347e+01,\n",
       "         1.678434e-02, -1.364941e-02,  3.043375e-02,  1.880000e+02,\n",
       "         1.920000e+02,  3.254944e-05,  2.025712e-07, -7.458378e-06,\n",
       "         5.730453e-06,  2.393948e-03,  1.012941e+00,  2.028402e+01,\n",
       "         2.492777e+00, -6.001552e+00,  8.494328e+00,  1.990000e+02,\n",
       "         1.880000e+02,  1.877852e-02,  3.604794e-04, -5.241616e-02,\n",
       "         6.510860e-01,  8.079506e-01, -2.715628e+00,  1.965194e+01,\n",
       "         1.752997e+00, -3.535505e+00,  5.288502e+00,  2.460000e+02,\n",
       "         3.200000e+02, -3.438899e-02, -2.577087e-04,  1.650849e-02,\n",
       "         4.347848e-01,  6.600399e-01, -1.320223e+00,  7.389727e+00,\n",
       "         4.584801e+00, -3.505112e+00,  8.089913e+00,  1.880000e+02,\n",
       "         3.190000e+02, -2.578006e-02, -3.005291e-04,  3.357443e-02,\n",
       "         7.572187e-01,  8.708611e-01,  4.836921e-01,  7.262692e+00,\n",
       "         3.254681e+00, -3.450635e+00,  6.705316e+00,  2.160000e+02,\n",
       "         3.190000e+02, -1.875895e-02, -7.088238e-05, -4.759683e-03,\n",
       "         8.375319e-01,  9.152036e-01, -4.453008e-01,  4.746503e+00,\n",
       "         3.152836e+00, -3.575074e+00,  6.727910e+00,  3.030000e+02,\n",
       "         1.870000e+02,  1.843364e-03,  2.553848e-04, -4.859513e-02,\n",
       "         9.073909e-01,  9.530180e-01, -2.060299e-01,  4.055768e+00,\n",
       "         3.540468e+00, -4.973225e+00,  8.513693e+00,  2.030000e+02,\n",
       "         1.990000e+02,  2.038510e-02,  3.906956e-04, -5.677729e-02,\n",
       "         1.241077e+00,  1.114931e+00, -3.326147e-01,  4.847927e+00,\n",
       "         5.076632e+00, -5.213991e+00,  1.029062e+01,  1.870000e+02,\n",
       "         2.460000e+02,  1.220495e-02,  9.488482e-05, -6.534800e-03,\n",
       "         1.306025e+00,  1.142866e+00,  1.623464e-01,  5.867389e+00,\n",
       "         6.829482e+00, -4.210305e+00,  1.103979e+01,  2.460000e+02,\n",
       "         2.530000e+02, -1.094814e-02,  3.372181e-04, -7.754872e-02,\n",
       "         1.836599e+00,  1.355760e+00,  3.423044e-01,  6.057432e+00,\n",
       "         4.309529e+00, -5.162860e+00,  9.472389e+00,  2.250000e+02,\n",
       "         2.170000e+02, -1.188867e-02,  4.188391e-05, -2.016074e-02,\n",
       "         1.470729e+00,  1.212745e+00, -4.247525e-01,  4.926879e+00,\n",
       "         3.338694e+00, -4.074242e+00,  7.412936e+00,  2.280000e+02,\n",
       "         2.250000e+02, -7.835488e-03, -2.542444e-04,  4.237777e-02,\n",
       "         1.029402e+00,  1.015011e+00, -2.549691e-01,  3.799232e+00,\n",
       "         3.438033e+00, -4.478361e+00,  7.916393e+00,  3.930000e+02,\n",
       "         1.870000e+02,  1.145244e-04,  6.683734e-05, -1.308585e-02,\n",
       "         1.165528e+00,  1.079623e+00, -1.751494e-01,  3.898173e+00,\n",
       "         3.061810e+00, -3.176090e+00,  6.237901e+00,  3.240000e+02,\n",
       "         1.990000e+02, -2.559434e-02, -2.813370e-04,  2.996972e-02,\n",
       "         1.103184e+00,  1.050818e+00, -9.303259e-02,  3.237349e+00,\n",
       "         2.768208e-02, -1.441523e-02,  4.209731e-02,  1.880000e+02,\n",
       "         7.400000e+01, -5.296238e-05, -1.629056e-06,  2.687761e-04,\n",
       "         2.711123e-05,  5.210174e-03,  1.057681e+00,  7.067499e+00,\n",
       "         1.644809e-01, -1.053787e-01,  2.698597e-01,  3.190000e+02,\n",
       "         3.330000e+02,  5.916216e-04,  7.671971e-07,  4.401002e-04,\n",
       "         6.344896e-04,  2.518923e-02,  1.175278e+00,  1.312128e+01,\n",
       "         8.886503e+01, -1.004090e+02,  1.892740e+02,  3.210000e+02,\n",
       "         3.340000e+02, -1.219186e-08, -1.354808e-03,  2.675745e-01,\n",
       "         2.232753e+02,  1.494320e+01, -1.123804e+00,  2.887559e+01]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-bef723c5bc73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMyModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/anaconda3/envs/ning/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m    594\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'layer'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([404., 385., 178.,   4., 462., 363., 131., 378.,  88., 348.])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:10,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541    0\n",
       "570    0\n",
       "514    0\n",
       "534    0\n",
       "522    0\n",
       "524    0\n",
       "539    0\n",
       "552    0\n",
       "590    0\n",
       "521    1\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2581"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1107"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1235"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"label\"]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2453"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"label\"]==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3688"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1235+2453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
